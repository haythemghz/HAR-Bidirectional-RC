Ref: Submission ID d8fb70c7-2bf9-40cd-9cbd-1caf202c8b7f

Dear Dr Barhoumi,

Your manuscript "Bidirectional Reservoir Computing for Enhanced Human Action Recognition Using Skeleton Data" has now been assessed. If there are any reviewer comments on your manuscript, you can find them at the end of this email.

Regrettably, your manuscript has been rejected for publication in International Journal of Machine Learning and Cybernetics.

Editor Comments

"The reviewers have some comments to improve the manuscript. Please carefully address them point to point during the revision."
-Hao Peng

Thank you for the opportunity to review your work. I'm sorry that we cannot be more positive on this occasion and hope you will not be deterred from submitting future work to International Journal of Machine Learning and Cybernetics.

Kind regards,

Xizhao Wang
Editor
International Journal of Machine Learning and Cybernetics

While I'm sorry we cannot publish your work in International Journal of Machine Learning and Cybernetics, your manuscript may be a good fit for one of our other journals. At Springer Nature we provide a free service to give authors a range of personalised journal recommendations. The corresponding author will receive an email with more information in the next 2 days. 

Reviewer Comments:

Reviewer 1
There are fundamental problems in the article including not limited to:
1.    The manuscript contains several tortured phrases and non-standard expressions that deviate from well-established terminology. For example:
elegantly sidestep => effectively address / mitigate
computational burdens => computational overhead
weaves => integrates
fraught => present
Chief among these => most significant of these
elegance => effectively
weaves together => integrates
tapestry of spatiotemporal information => a sequence of spatiotemporal feature vectors   
2.    The manuscript does not clearly articulate the motivation for adopting a bidirectional approach, particularly given that bidirectional RNNs have already been extensively explored for similar sequence modeling tasks.
3.    The authors identify the vanishing and exploding gradient problem as a key motivation for their work; however, the experimental evaluation does not include any analysis or evidence demonstrating that the proposed approach effectively mitigates these issues.
4.    Figure 1 does not adhere to standard diagrammatic conventions and is overly abstract, making it difficult to understand the proposed framework.
5.    Evaluations should report F1-scores for corresponding methods.
6.    Qualitative and user perceptual studies are missing.
7.    Section "5.1 Dataset Analysis" should be retitled to "5.1 Datasets".
8.    The authors should include confusion matrices for activity classification to illustrate class-wise performance and potential misclassifications.
9.    The results reported in Figure 2 are not adding any value to the final evaluation of the study.
10.    The authors should address the concern that, while comprehensive, the proposed framework appears overly complex, incorporating numerous components and hyperparameters. This raises the possibility that the approach may be over-engineered.
11.    Although the experiments are extensive across the three selected datasets, the evaluation lacks large-scale or more diverse benchmarks, such as the widely used NTU RGB+D 60/120 or other in-the-wild action recognition datasets.
12.    The paper compares against many prior methods, but most of those baselines date up to around 2020–2021
13.    The reported accuracies (97–99%) on the selected datasets are exceptionally high. While this demonstrates strong performance, it also raises concerns about potential overfitting, given the relatively small dataset sizes.
14.    The claim that the proposed approach reduces training time by 95% and inference time by 93% compared to LSTM networks requires empirical justification.
15.    The authors should discuss how well the proposed RC framework generalizes beyond skeleton-based human action recognition, particularly to other sequential or temporal domains.
16.    The claim of novelty regarding the use of bidirectional temporal processing for human action recognition is not fully justified, as several prior studies have already explored this concept.
S. Li et al., "HARMamba: Efficient and Lightweight Wearable Sensor Human Activity Recognition Based on Bidirectional Mamba," in IEEE Internet of Things Journal, vol. 12, no. 3, pp. 2373-2384, 1 Feb.1, 2025, doi: 10.1109/JIOT.2024.3463405.
Gallicchio, C. and Micheli, A., 2016, November. A Reservoir Computing Approach for Human Gesture Recognition from Kinect Data. In AI* AAL@ AI* IA (pp. 33-42).
Khan, I. U., & Lee, J. W. (2024). PAR-Net: An Enhanced Dual-Stream CNN–ESN Architecture for Human Physical Activity Recognition. Sensors, 24(6), 1908.  https://doi.org/10.3390/s24061908
17.    The following references do not appear to exist and are probably hallucinated, which raises the concerns over the authenticity of the study:
[1] Wang, Y., Li, X., Chen, M., Zhang, W.: Privacy implications of skeleton based action recognition: A systematic analysis. Computer Vision and Image Understanding 228, 103621 (2023)
[2] Chen, X., Wang, L., Zhang, H., Liu, J.: Privacy-preserving human action recognition
using skeleton data: A comprehensive survey. IEEE Transactions on Information Forensics and Security 16, 3045–3060 (2021)
[3] Zhang, H., Liu, J., Wang, L., Chen, X.: Robust human action recognition under varying environmental conditions: A comparative study. Pattern Recognition 134, 109087 (2023)
[4] Liu, J., Zhang, H., Wang, L., Chen, X.: Environmental robustness in skeleton based human action recognition: Challenges and solutions. IEEE Transactions on Multimedia 25, 4567–4580 (2023)
[5] Chen, M., Wang, Y., Li, X., Zhang, W.: Computational efficiency analysis of deep learning approaches for human action recognition. IEEE Transactions on Neural Networks and Learning Systems 34(8), 4123–4136 (2023)
[6] Wang, L., Chen, X., Zhang, H., Liu, J.: Appearance-invariant human action recognition: Methods and evaluation. International Journal of Computer Vision 131(7), 1789–1812 (2023)
[7] Zhang, W., Li, X., Wang, Y., Chen, M.: A comparative study of rgb-based and skeleton-based approaches for human action recognition. Computer Vision and Image Understanding 229, 103645 (2023)
[8] Liu, X., Wang, J., Chen, Y., Zhang, K.: Multi-modal vs. single-modal approaches in human action recognition: A comprehensive evaluation. Pattern Recognition 135, 109156 (2023)
[9] Chen, Y., Liu, X., Wang, J., Zhang, K.: Skeleton-based human action recognition: Recent advances and future directions. IEEE Transactions on Pattern Analysis and Machine Intelligence 45(6), 7234–7251 (2023)
18.    Recheck the reference [25]


Reviewer 2
1. The introduction could benefit from a clearer statement of research gap just before the contributions — what precisely has not been addressed by prior RC-based or LSTM-based models for skeleton HAR? Discuss the main contributions in points.
2. The claim that this is the “first comprehensive bidirectional RC architecture for skeleton-based HAR” needs support. Can the authors cite and contrast with existing RC-based works to support this contribution?
3. The integration of PCA and Tucker decomposition is described as adaptive multi-view reduction. Could the authors clarify: How are the multiple “views” defined (e.g., spatial, temporal, or skeletal joint groups)? Is this adaptivity data-driven or parameter-driven?
4. Are the forward and backward reservoirs concatenated, averaged, or combined through another operation (e.g., gating or attention)? Discuss how bidirectional information is fused.
5. The paper mentions an advanced readout mechanism with nonlinear activations. Which specific nonlinearities or optimization strategies were found most effective?
6. How are reservoir hyperparameters (e.g., spectral radius, sparsity, leak rate) tuned for bidirectional dynamics? Is there an adaptive strategy?
7. Since reservoir computing inherently relies on fixed random weights in the recurrent layer, how does the bidirectionality affect the stability and echo state property?
8. The statement “drastically reducing training time by 95% and inference time by 93% compared to LSTM networks” is impressive but needs explicit clarification. Was this reduction measured under identical training conditions?
9. It would be valuable to provide comparative baselines beyond LSTM — for instance, comparisons with GCN-based or Transformer-based skeleton models (e.g., ST-GCN, PoseFormer).
10. The authors should briefly discuss the following papers related to Action Recognition:
(a) Tian, Q., Li, S., Zhang, Y., Lu, H., & Pan, H. (2025). Action recognition method based on a novel keyframe extraction method and enhanced 3D convolutional neural network. International Journal of Machine Learning and Cybernetics, 16(1), 475-491.
(b) Dey, A., Biswas, S., & Le, D. N. (2024). Workout Action Recognition in Video Streams Using an Attention Driven Residual DC-GRU Network. Computers, Materials and Continua, 79(2), 3067-3087.
11. Show some test results in the manuscript.
12. The Tucker decomposition step implies tensorization of features. What is the computational overhead of this step relative to the savings from avoiding LSTM training?

Reviewer 3
1.    Dataset Diversity: The study uses only three moderate-sized datasets (UTD-MHAD, MSR Action3D, CZU-MHAD). Can the authors test the framework on larger or cross-dataset benchmarks (e.g., NTU-RGB+D) to validate scalability and generalization?
2.    Comparative Baselines: While graph-based and RNN-based methods are compared, why are transformer-based skeleton models (e.g., ST-TR, PoseFormer) excluded from evaluation, given their current prominence in HAR research?
3.    Reservoir Configuration Justification: How were the reservoir hyperparameters (spectral radius, leak rate, sparsity) selected? Please provide a sensitivity analysis to demonstrate model stability across configurations.
4.    Dimensionality Reduction Impact: The PCA + Tucker decomposition pipeline claims 95% variance retention. How does this compression affect class separability? Can authors show a t-SNE or UMAP visualization before and after reduction?
5.    Computational Efficiency Validation: Reported time savings (95% training, 93% inference) are impressive—can these be quantitatively verified using FLOPs, runtime comparisons, or hardware-independent benchmarks?
6.    Statistical Significance: The paper reports high accuracies (up to 98.9%), but lacks statistical confidence intervals. Can the authors include standard deviations or confidence levels over multiple runs?
7.    Model Interpretability: The proposed attention and fusion mechanisms are theoretically sound—could the authors include attention heatmaps or interpretability analysis to show how the model distinguishes similar actions?
8.    Ablation Completeness: While progressive ablation is thorough, it omits cross-component interaction effects. How do combinations of bidirectionality, PCA, and Tucker interact when removed jointly?
9.    Real-Time Feasibility: Given the claim of lightweight design, can the authors demonstrate real-time inference feasibility on embedded or low-power devices (e.g., Jetson Nano or Raspberry Pi)?
10.    Future Scope and Limitations: The conclusion is optimistic but lacks discussion of limitations (e.g., noise sensitivity, generalization to occluded joints). Can the authors add a section addressing potential weaknesses and future extensions?
